<title>CS230: Background and Computer History</title>
<h1>CS230: Background and Computer History</h1>
<h3>
    <ul>
        <li><a href="main.html">Back to Main Lecture Notes</a></li>
        <li>Last Updated: 9/27/2023</li>
    </ul>
</h3>
<hr>
<h2>Classes of Computers</h2>
There are 4 main classes of computers that are examined in this class. They are:
<ul>
    <li>Personal Computers</li>
    <li>Server Computers</li>
    <li>Super Computers</li>
    <li>Embedded Computers</li>
</ul>

<b>Personal computers</b> are self explanatory, they are the same thing that you are probably 
viewing this website on. They are versatile, general purpose machines designed for a broad 
range of different use-cases, from gaming to word processing.
<br></br>
<b>Server computers</b> are a bit different. Servers are computers that that provides resources, 
data, services, or programs to other computers, known as clients, over a network connection. 
When you go to view this page, one of GitHub's servers is handling the behind-the-scenes work 
of sending the data to your browser to be displayed. Servers are also generally build for 
high-uptime and high density use cases, where reliability and power efficiency are of paramount 
importance to the company operating them. Servers can also range in scale, from a 1U unit in a 
small business that records security camera footage, to large scale data center servers like those 
owned by Google.
<br></br>
<b>Super computers</b> can generally be thought of as servers on steroids. They are generally build for 
high throughput, high performance scientific applications, such as high fidelity physics simulations. 
Super computers generally differ from PCs and servers in their performance. For example, while your gaming PC 
may be able to perform tens of terraflops per second, most supercomputers perform in the hundreds of petaflops range 
(more on the FLOPS performance metric later).
<br></br>
<b>Embedded computers</b> are usually small, specialized computers that are <i>embedded</i> within a larger mechanism. For 
example, the engine control unit (ECU) that regulates your car's engine would be an example of an embedded computer. These 
are generally subject to pretty tight design constraints, including power consumption, reliability, and very limited 
processing power and memory.
<br></br>
While those are the main 4 types of computers, it's also important to recognize two additional types of computers:
<br>
<ul>
    <li>Personal Mobile Devices</li>
    <li>Cloud Computing</li>
</ul>
<b>Personal mobile devices</b> are things like your smartphone. They run on battery, connect to the internet, and have more limited 
processing power, since they mainly are intended for things like web browsing, phone calls, emails, and photo taking.
<br></br>
<b>Cloud computing</b> covers a variety of services. Cloud computing generally refers the practice of using a network of remote servers 
hosted on the internet to store, manage, and process data, rather than a local server or a personal computer. This can include multiple 
services such as SaaS (software as a service, google drive would be an example), and warehouse-scale computing (an example would be GMail, 
Apple Maps, or the Google search engine).
<br></br>
<hr>
<h2>History of the Computer</h2>
Computers have evolved at an exponential pace since their conception in the mid-20th century. To have a proper grasp on 
the fundamentals of computer architecure and design choices, it helps to have some historical perspective.
<br>
<h3>The ENIAC</h3>
The first computer was the ENIAC (Electronic Numerical Integrator And Computer), designed and constructed by the University of Pennsylvania as part of the WW2 war effort. 
This primitive computer was intended to calculate artillery firing tables for allied artillery pieces in use against the axis powers. The project was started in 1943, 
and finished in 1946, too late to make any strategic impact on the war effort. However, it was accepted by the Army Corps of Engineers
in 1946 and was in use at Aberdeen Proving Ground in Maryland until 1955. The ENIAC was massive, spanning 15,000 square feet, and weighed 30 tons. 
As this was before the invention of the transistor, the ENIAC used thousands of vacuum tubes in its circuitry. It however was Turing complete, and could perform 5000 additions per second and had to be programmed manually.
<br>
<h3>Von Neumann Architecture</h3>
The Von Neumann architecture was the next major step in the evolution toward modern computers. Von Neumann architecture describes a computer architecture 
for an electronic digital computer with these components:
<ul>
    <li>ALU (Arithmetic Logic Unit)</li>
    <li>Program Control Unit</li>
    <li>Main Memory</li>
    <li>I/O Equipment</li>
</ul> 
Where the control unit would interpret instructions from programs stored in main memory and execute them, the ALU would handle arithmetic operations, and the I/O equipment 
would serve as a human interface device.
<br>
<h3>The Transistor</h3>
Prior to the inception of the transistor, vacuum tubes were used to regulate electric flow inside of a computer's circuitry. Invented in 1947 
at Bell Labs, the transistor offered many advantages to vacuum tubes while fulfilling an identical function. The transistor was smaller, cheaper, 
generated less heat dissipation, and was a solid state device, none of which could be said about vacuum tubes.
<br></br>
The transistor allowed computers to shrink by orders of magnitude. Machines that would take up entire warehouses could be functionally 
replaced by a machine that took up only a single room. This lead to the feasibility of commercial computers and second-generation 
machines, such as the <a href="https://en.wikipedia.org/wiki/IBM_700/7000_series">IMB 7000</a>. 
<br>
<h3>Semiconductor Memory</h3>
The next big advancement in computer tech was the introduction of semiconductor memory. Devised by Fairchild in 1970, semiconductor memory 
offered several new features compared to previous magnetic core memory techniques, including a reduction in physical size by orders 
of magnitude, could hold more bits of information, was much faster than a magnetic core memory, and allowed performing read operations 
in a non-destructive manner (with magnetic core memory, due to design limitations, when you tried to read a bit, no matter what it was previously set to, 
it would be set to 0). The capacity and size of semiconductor memory improved exponentially since 1970, and nowadays we are offended by an M.2 drive 
that holds less than a terrabyte, when the equivalent magnetic core memory would span buildings.
<br>
<h3>The First Microprocessor</h3>
This is when we first start to see something that looks like modern hardware. The Intel 4004, created in 1971, was the first instance 
of a microprocessor, where all of the CPU components were contained on a single chip. The 4004 was a 4-bit processor used for arithmetic 
operation and the Busicom calculator.
<br></br>
We've now essentially hit all the biggest developments that lead-up to the modern computer.
<br>
<hr>
<br>